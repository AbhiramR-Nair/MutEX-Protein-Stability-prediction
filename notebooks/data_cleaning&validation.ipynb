{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "K50 Protein Stability Dataset Processing Pipeline\n",
    "\n",
    "This module processes the K50 dG dataset to extract and validate single-point \n",
    "mutations for protein stability prediction tasks. The pipeline performs:\n",
    "1. Data loading and feature selection\n",
    "2. Filtering for single-point mutations\n",
    "3. Mutation annotation parsing\n",
    "4. Wild-type sequence reconstruction\n",
    "5. Mutation validation\n",
    "6. Stability classification\n",
    "7. Dataset export\n",
    "\n",
    "Author: ML Research Team\n",
    "Date: 2025\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Suppress pandas warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# File paths\n",
    "INPUT_PATH = Path(r'D:\\ML_Project\\K50 data\\Processed_K50_dG_datasets\\K50_dG_Dataset1_Dataset2.csv')\n",
    "OUTPUT_PATH = Path('k50_cleaned.csv')\n",
    "\n",
    "# Regex pattern to parse mutation strings (e.g., \"A123G\" -> wild-type A, position 123, mutant G)\n",
    "MUTATION_PATTERN = re.compile(r'([A-Za-z]+)(\\d+)([A-Za-z]+)')\n",
    "\n",
    "# Column names to retain from the raw dataset\n",
    "FEATURES_TO_KEEP = [\n",
    "    'name',           # Mutation/protein identifier\n",
    "    'aa_seq',         # Amino acid sequence (mutant)\n",
    "    'ddG_ML',         # Predicted change in Gibbs free energy\n",
    "    'mut_type',       # Mutation annotation (e.g., \"A123G\")\n",
    "    'WT_name',        # Wild-type protein identifier\n",
    "    'WT_cluster'      # Protein family/cluster identifier\n",
    "]\n",
    "\n",
    "# Stability classification threshold\n",
    "# Mutations with ddG < 0 are stabilizing (class 0)\n",
    "# Mutations with ddG >= 0 are destabilizing (class 1)\n",
    "STABILITY_THRESHOLD = 0.0\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# DATA LOADING\n",
    "# =============================================================================\n",
    "\n",
    "def load_k50_dataset(filepath: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load the K50 dataset from a CSV file with validation.\n",
    "    \n",
    "    This function reads the complete K50 dataset and performs basic validation\n",
    "    to ensure the file exists and contains data.\n",
    "    \n",
    "    Args:\n",
    "        filepath: Path object pointing to the K50 dataset CSV file\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Complete dataset with all original columns\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundError: If the specified file does not exist\n",
    "        ValueError: If the CSV file is empty after loading\n",
    "        \n",
    "    Example:\n",
    "        >>> df = load_k50_dataset(Path('data/k50_dataset.csv'))\n",
    "        Loaded dataset shape: (851552, 38)\n",
    "    \"\"\"\n",
    "    # Check if file exists before attempting to read\n",
    "    if not filepath.exists():\n",
    "        raise FileNotFoundError(f\"Dataset not found at: {filepath}\")\n",
    "    \n",
    "    # Load CSV into DataFrame\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    # Validate that we actually loaded data\n",
    "    if df.empty:\n",
    "        raise ValueError(\"Loaded dataset is empty\")\n",
    "    \n",
    "    # Print diagnostic information\n",
    "    print(f\"Loaded dataset shape: {df.shape}\")\n",
    "    print(f\"Columns: {df.columns.tolist()}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# FEATURE SELECTION AND FILTERING\n",
    "# =============================================================================\n",
    "\n",
    "def select_features(df: pd.DataFrame, features: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract a subset of columns from the dataset.\n",
    "    \n",
    "    This function selects only the columns needed for downstream processing,\n",
    "    reducing memory usage and simplifying the dataset.\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame with all columns\n",
    "        features: List of column names to retain\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Copy of the input with only selected columns\n",
    "        \n",
    "    Raises:\n",
    "        KeyError: If any requested feature is not present in the DataFrame\n",
    "        \n",
    "    Example:\n",
    "        >>> features = ['name', 'aa_seq', 'ddG_ML']\n",
    "        >>> df_subset = select_features(df_raw, features)\n",
    "    \"\"\"\n",
    "    # Check that all requested features exist in the DataFrame\n",
    "    missing_features = set(features) - set(df.columns)\n",
    "    if missing_features:\n",
    "        raise KeyError(f\"Missing features in dataset: {missing_features}\")\n",
    "    \n",
    "    # Return a copy to avoid modifying the original DataFrame\n",
    "    return df[features].copy()\n",
    "\n",
    "\n",
    "def filter_single_point_mutations(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filter dataset to retain only valid single-point mutations.\n",
    "    \n",
    "    This function removes:\n",
    "    1. Wild-type sequences (mut_type == 'wt' or 'WT')\n",
    "    2. Multiple mutations (indicated by ':' in mutation string)\n",
    "    3. Insertions and deletions (starting with 'ins' or 'del')\n",
    "    \n",
    "    Why filter these?\n",
    "    - Wild-type sequences have no mutation (ddG should be 0)\n",
    "    - Multiple mutations are complex and harder to model\n",
    "    - Indels require different processing than substitutions\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame with 'mut_type' column\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Filtered DataFrame containing only single-point substitutions\n",
    "        \n",
    "    Example:\n",
    "        >>> df_filtered = filter_single_point_mutations(df)\n",
    "        Original records: 851552\n",
    "        After filtering: 375560\n",
    "        Removed: 475992 records\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the input\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Ensure mut_type is a clean string (remove leading/trailing whitespace)\n",
    "    df['mut_type'] = df['mut_type'].astype(str).str.strip()\n",
    "    \n",
    "    # Create boolean masks for filtering\n",
    "    # Mask 1: Exclude wild-type sequences (case-insensitive)\n",
    "    not_wt = ~df['mut_type'].str.lower().eq('wt')\n",
    "    \n",
    "    # Mask 2: Exclude multiple mutations (contain ':' separator)\n",
    "    # Example of multiple mutation: \"A123G:T456A\"\n",
    "    not_multiple = ~df['mut_type'].str.contains(':', na=False)\n",
    "    \n",
    "    # Mask 3: Exclude insertions and deletions\n",
    "    # These start with 'ins' or 'del' in the mutation string\n",
    "    not_indel = ~df['mut_type'].str.startswith(('del', 'ins'), na=False)\n",
    "    \n",
    "    # Combine all masks with AND logic\n",
    "    mask = not_wt & not_multiple & not_indel\n",
    "    \n",
    "    # Apply the combined filter\n",
    "    filtered_df = df[mask].copy()\n",
    "    \n",
    "    # Report filtering statistics\n",
    "    print(f\"Original records: {len(df)}\")\n",
    "    print(f\"After filtering: {len(filtered_df)}\")\n",
    "    print(f\"Removed: {len(df) - len(filtered_df)} records\")\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MUTATION PARSING\n",
    "# =============================================================================\n",
    "\n",
    "def parse_mutation(mutation_str: str) -> Optional[Tuple[str, int, str]]:\n",
    "    \"\"\"\n",
    "    Parse a mutation string into its constituent components.\n",
    "    \n",
    "    Mutation strings follow the format: <WT_residue><position><Mutant_residue>\n",
    "    - WT_residue: Original amino acid (1 or 3 letter code)\n",
    "    - position: 1-indexed position in the sequence\n",
    "    - Mutant_residue: Mutated amino acid (1 or 3 letter code)\n",
    "    \n",
    "    Args:\n",
    "        mutation_str: Mutation annotation string (e.g., \"A123G\" or \"Ala123Gly\")\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (wild_type_residue, position, mutant_residue) if parsing succeeds\n",
    "        None if the string doesn't match the expected format\n",
    "        \n",
    "    Example:\n",
    "        >>> parse_mutation(\"A123G\")\n",
    "        ('A', 123, 'G')\n",
    "        >>> parse_mutation(\"Ala123Gly\")\n",
    "        ('Ala', 123, 'Gly')\n",
    "        >>> parse_mutation(\"invalid\")\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Attempt to match the mutation pattern\n",
    "    match = MUTATION_PATTERN.match(mutation_str)\n",
    "    \n",
    "    if match:\n",
    "        # Extract the three components from the regex groups\n",
    "        wt_residue, position, mut_residue = match.groups()\n",
    "        \n",
    "        # Convert position to integer for numerical operations\n",
    "        return wt_residue, int(position), mut_residue\n",
    "    \n",
    "    # Return None if parsing fails\n",
    "    return None\n",
    "\n",
    "\n",
    "def annotate_mutations(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parse mutation strings and add structured annotation columns.\n",
    "    \n",
    "    This function decomposes the 'mut_type' string into three separate columns\n",
    "    for easier downstream processing and validation.\n",
    "    \n",
    "    Added columns:\n",
    "    - wt_residue: Wild-type amino acid\n",
    "    - mutation_position: 1-indexed position in the sequence\n",
    "    - mutated_residue: Mutant amino acid\n",
    "    \n",
    "    Records that cannot be parsed are removed from the output.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with 'mut_type' column\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with added mutation annotation columns\n",
    "        \n",
    "    Example:\n",
    "        >>> df_annotated = annotate_mutations(df_filtered)\n",
    "        Successfully parsed 375560 mutations\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Apply parsing function to each mutation string\n",
    "    parsed = df['mut_type'].apply(parse_mutation)\n",
    "    \n",
    "    # Remove records where parsing failed (returned None)\n",
    "    df = df[parsed.notna()].copy()\n",
    "    parsed = parsed[parsed.notna()]\n",
    "    \n",
    "    # Extract individual components from the tuple\n",
    "    # Lambda functions are used to access tuple elements by index\n",
    "    df['wt_residue'] = parsed.apply(lambda x: x[0])           # Wild-type amino acid\n",
    "    df['mutation_position'] = parsed.apply(lambda x: x[1])    # Position (int)\n",
    "    df['mutated_residue'] = parsed.apply(lambda x: x[2])      # Mutant amino acid\n",
    "    \n",
    "    # Report how many mutations were successfully parsed\n",
    "    print(f\"Successfully parsed {len(df)} mutations\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# WILD-TYPE SEQUENCE RECONSTRUCTION\n",
    "# =============================================================================\n",
    "\n",
    "def reconstruct_wt_sequence(mutant_seq: str, mutation_str: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Reconstruct the wild-type sequence from mutant sequence and mutation annotation.\n",
    "    \n",
    "    This is essentially \"reversing\" the mutation:\n",
    "    - We know the mutant sequence\n",
    "    - We know what position was mutated and what it was changed to\n",
    "    - We can substitute back the wild-type residue to get the original sequence\n",
    "    \n",
    "    Validation checks:\n",
    "    1. Position must be within sequence bounds (not negative, not beyond sequence length)\n",
    "    2. The mutant sequence must have the expected mutant residue at the position\n",
    "    \n",
    "    Args:\n",
    "        mutant_seq: Amino acid sequence of the mutant protein\n",
    "        mutation_str: Mutation annotation (e.g., \"A123G\")\n",
    "        \n",
    "    Returns:\n",
    "        Reconstructed wild-type sequence string, or None if reconstruction fails\n",
    "        \n",
    "    Example:\n",
    "        >>> mutant = \"MKGLWSKSSVIG\"\n",
    "        >>> mutation = \"K2G\"  # Position 2 changed from K to G\n",
    "        >>> reconstruct_wt_sequence(mutant, mutation)\n",
    "        'MKKLWSKSSVIG'  # G at position 2 changed back to K\n",
    "    \"\"\"\n",
    "    # Parse the mutation string\n",
    "    parsed = MUTATION_PATTERN.match(mutation_str)\n",
    "    if not parsed:\n",
    "        return None\n",
    "    \n",
    "    # Extract components\n",
    "    wt_residue, position, mut_residue = parsed.groups()\n",
    "    \n",
    "    # Convert from 1-indexed (biological convention) to 0-indexed (Python)\n",
    "    position_idx = int(position) - 1\n",
    "    \n",
    "    # Validate that position is within sequence bounds\n",
    "    if position_idx < 0 or position_idx >= len(mutant_seq):\n",
    "        return None\n",
    "    \n",
    "    # Validate that the mutant sequence has the expected mutant residue\n",
    "    # This is a consistency check - if it fails, the annotation is wrong\n",
    "    if mutant_seq[position_idx] != mut_residue:\n",
    "        return None\n",
    "    \n",
    "    # Reconstruct WT sequence by substituting the wild-type residue\n",
    "    # String slicing: [before mutation] + [WT residue] + [after mutation]\n",
    "    wt_seq = mutant_seq[:position_idx] + wt_residue + mutant_seq[position_idx + 1:]\n",
    "    \n",
    "    return wt_seq\n",
    "\n",
    "\n",
    "def add_wt_sequences(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add reconstructed wild-type sequences to the DataFrame.\n",
    "    \n",
    "    This function applies the reconstruction logic to every row in the dataset,\n",
    "    creating a new column 'WT_sequence' that contains the original (pre-mutation)\n",
    "    sequence for each protein.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with 'aa_seq' (mutant) and 'mut_type' columns\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with added 'WT_sequence' column\n",
    "        \n",
    "    Example:\n",
    "        >>> df_with_wt = add_wt_sequences(df_annotated)\n",
    "        Successfully reconstructed 375560/375560 WT sequences\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Apply reconstruction function to each row\n",
    "    # axis=1 means apply function across columns (row-wise)\n",
    "    df['WT_sequence'] = df.apply(\n",
    "        lambda row: reconstruct_wt_sequence(row['aa_seq'], row['mut_type']),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Count how many sequences were successfully reconstructed\n",
    "    num_reconstructed = df['WT_sequence'].notna().sum()\n",
    "    print(f\"Successfully reconstructed {num_reconstructed}/{len(df)} WT sequences\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MUTATION VALIDATION\n",
    "# =============================================================================\n",
    "\n",
    "def validate_mutation(mutant_seq: str, wt_seq: str, mutation_str: str) -> bool:\n",
    "    \"\"\"\n",
    "    Validate that mutation annotation is consistent with both sequences.\n",
    "    \n",
    "    This is a critical quality control step. We verify three things:\n",
    "    1. Position is within bounds (not out of range)\n",
    "    2. Mutant sequence has the mutant residue at the specified position\n",
    "    3. Wild-type sequence has the WT residue at the specified position\n",
    "    \n",
    "    Why is this important?\n",
    "    - Catches data entry errors\n",
    "    - Catches alignment issues\n",
    "    - Ensures our reconstruction was correct\n",
    "    - Prevents training ML models on corrupted data\n",
    "    \n",
    "    Args:\n",
    "        mutant_seq: Mutant amino acid sequence\n",
    "        wt_seq: Wild-type amino acid sequence\n",
    "        mutation_str: Mutation annotation (e.g., \"A123G\")\n",
    "        \n",
    "    Returns:\n",
    "        True if all validation checks pass, False otherwise\n",
    "        \n",
    "    Example:\n",
    "        >>> wt = \"MKKLWSKSSVIG\"\n",
    "        >>> mut = \"MKGLWSKSSVIG\"\n",
    "        >>> validate_mutation(mut, wt, \"K2G\")\n",
    "        True\n",
    "        >>> validate_mutation(mut, wt, \"K2A\")  # Wrong mutant residue\n",
    "        False\n",
    "    \"\"\"\n",
    "    # Parse the mutation string\n",
    "    parsed = MUTATION_PATTERN.match(mutation_str)\n",
    "    if not parsed:\n",
    "        return False\n",
    "    \n",
    "    wt_residue, position, mut_residue = parsed.groups()\n",
    "    position_idx = int(position) - 1  # Convert to 0-indexed\n",
    "    \n",
    "    # Check 1: Position must be within sequence bounds\n",
    "    if position_idx < 0 or position_idx >= len(mutant_seq):\n",
    "        return False\n",
    "    \n",
    "    # Check 2: Mutant sequence must have the mutant residue at this position\n",
    "    if mutant_seq[position_idx] != mut_residue:\n",
    "        return False\n",
    "    \n",
    "    # Check 3: WT sequence must have the WT residue at this position\n",
    "    if wt_seq[position_idx] != wt_residue:\n",
    "        return False\n",
    "    \n",
    "    # All checks passed\n",
    "    return True\n",
    "\n",
    "\n",
    "def add_validation_flags(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add validation flag indicating whether each mutation is consistent.\n",
    "    \n",
    "    This function applies the validation logic to every row, creating a boolean\n",
    "    column that indicates whether the mutation annotation is trustworthy.\n",
    "    \n",
    "    Rows with is_valid_mutation=False should be investigated or removed.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with mutation data (must have aa_seq, WT_sequence, mut_type)\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with added 'is_valid_mutation' boolean column\n",
    "        \n",
    "    Example:\n",
    "        >>> df_validated = add_validation_flags(df_with_wt)\n",
    "        Validation results:\n",
    "          Valid mutations: 375560\n",
    "          Invalid mutations: 0\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Apply validation function to each row\n",
    "    df['is_valid_mutation'] = df.apply(\n",
    "        lambda row: validate_mutation(row['aa_seq'], row['WT_sequence'], row['mut_type']),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Count validation results\n",
    "    num_valid = df['is_valid_mutation'].sum()\n",
    "    num_invalid = (~df['is_valid_mutation']).sum()\n",
    "    \n",
    "    # Report statistics\n",
    "    print(f\"Validation results:\")\n",
    "    print(f\"  Valid mutations: {num_valid}\")\n",
    "    print(f\"  Invalid mutations: {num_invalid}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STABILITY CLASSIFICATION\n",
    "# =============================================================================\n",
    "\n",
    "def classify_stability(df: pd.DataFrame, threshold: float = 0.0) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Classify mutations based on their effect on protein stability.\n",
    "    \n",
    "    Classification scheme (binary):\n",
    "    - Class 0 (Stabilizing): ddG < threshold\n",
    "      These mutations make the protein MORE stable\n",
    "    - Class 1 (Destabilizing): ddG >= threshold\n",
    "      These mutations make the protein LESS stable or unchanged\n",
    "    \n",
    "    Why use ddG?\n",
    "    - ddG (delta-delta-G) represents the change in Gibbs free energy\n",
    "    - Negative ddG = mutation lowers energy = more stable folded state\n",
    "    - Positive ddG = mutation raises energy = less stable folded state\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with 'ddG_ML' column (predicted ddG values)\n",
    "        threshold: ddG threshold for classification (default: 0.0)\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with added 'ddG' and 'stability_class' columns\n",
    "        \n",
    "    Example:\n",
    "        >>> df_classified = classify_stability(df, threshold=0.0)\n",
    "        Stability classification (threshold=0.0):\n",
    "          Class 0 (Stabilizing, ddG < 0.0): 187234\n",
    "          Class 1 (Destabilizing, ddG >= 0.0): 188326\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Rename ddG_ML to ddG for clarity\n",
    "    # (ddG_ML indicates this is a machine learning prediction)\n",
    "    df['ddG'] = df['ddG_ML']\n",
    "    \n",
    "    # Binary classification: True (1) if destabilizing, False (0) if stabilizing\n",
    "    # The .astype(int) converts boolean to integer (True->1, False->0)\n",
    "    df['stability_class'] = (df['ddG'] >= threshold).astype(int)\n",
    "    \n",
    "    # Report class distribution for quality control\n",
    "    class_counts = df['stability_class'].value_counts().sort_index()\n",
    "    print(f\"Stability classification (threshold={threshold}):\")\n",
    "    print(f\"  Class 0 (Stabilizing, ddG < {threshold}): {class_counts.get(0, 0)}\")\n",
    "    print(f\"  Class 1 (Destabilizing, ddG >= {threshold}): {class_counts.get(1, 0)}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# FINAL DATA PREPARATION\n",
    "# =============================================================================\n",
    "\n",
    "def prepare_final_dataset(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prepare final cleaned dataset with standardized column names and ordering.\n",
    "    \n",
    "    This function:\n",
    "    1. Renames columns to consistent, clear names\n",
    "    2. Reorders columns in a logical sequence\n",
    "    3. Validates that all required columns exist\n",
    "    \n",
    "    Column naming conventions:\n",
    "    - wt_* : Wild-type related\n",
    "    - mut_* : Mutant related\n",
    "    - *_seq : Sequence data\n",
    "    - *_res : Residue (amino acid)\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame with all processed columns\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with standardized column names and ordering\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If any required column is missing\n",
    "        \n",
    "    Example:\n",
    "        >>> df_final = prepare_final_dataset(df_classified)\n",
    "        Final dataset shape: (375560, 12)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Define column renaming mapping for clarity and consistency\n",
    "    column_mapping = {\n",
    "        'aa_seq': 'mut_seq',              # More explicit: this is the MUTANT sequence\n",
    "        'WT_sequence': 'wt_seq',          # Consistent naming: wt_seq\n",
    "        'WT_cluster': 'wt_cluster',       # Lowercase for consistency\n",
    "        'WT_name': 'wt_name',             # Lowercase for consistency\n",
    "        'mutation_position': 'pos',       # Shorter, clearer\n",
    "        'mutated_residue': 'mut_res',     # Consistent with mut_seq naming\n",
    "        'wt_residue': 'wt_res'            # Consistent with wt_seq naming\n",
    "    }\n",
    "    df = df.rename(columns=column_mapping)\n",
    "    \n",
    "    # Define final column order (logical grouping)\n",
    "    # Order: identifiers -> sequences -> mutation details -> predictions -> flags\n",
    "    final_columns = [\n",
    "        'name',                 # Mutation identifier\n",
    "        'wt_name',              # Wild-type protein identifier\n",
    "        'wt_cluster',           # Protein family/cluster\n",
    "        'wt_seq',               # Wild-type sequence\n",
    "        'mut_seq',              # Mutant sequence\n",
    "        'mut_type',             # Mutation annotation\n",
    "        'wt_res',               # Wild-type residue\n",
    "        'pos',                  # Mutation position\n",
    "        'mut_res',              # Mutant residue\n",
    "        'ddG',                  # Stability change prediction\n",
    "        'stability_class',      # Binary stability classification\n",
    "        'is_valid_mutation'     # Validation flag\n",
    "    ]\n",
    "    \n",
    "    # Validate that all required columns exist\n",
    "    missing_cols = set(final_columns) - set(df.columns)\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "    \n",
    "    # Select and reorder columns\n",
    "    df = df[final_columns]\n",
    "    \n",
    "    # Report final dataset information\n",
    "    print(f\"Final dataset shape: {df.shape}\")\n",
    "    print(f\"Final columns: {df.columns.tolist()}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def export_dataset(df: pd.DataFrame, output_path: Path) -> None:\n",
    "    \"\"\"\n",
    "    Export cleaned dataset to CSV file.\n",
    "    \n",
    "    This function:\n",
    "    1. Creates output directory if it doesn't exist\n",
    "    2. Writes DataFrame to CSV without row indices\n",
    "    3. Reports export statistics\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame to export\n",
    "        output_path: Path object for output CSV file\n",
    "        \n",
    "    Example:\n",
    "        >>> export_dataset(df_final, Path('k50_cleaned.csv'))\n",
    "        Dataset exported to: k50_cleaned.csv\n",
    "        Total records: 375560\n",
    "    \"\"\"\n",
    "    # Create parent directories if they don't exist\n",
    "    # parents=True: create intermediate directories\n",
    "    # exist_ok=True: don't raise error if directory already exists\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Write to CSV\n",
    "    # index=False: don't write row numbers to file\n",
    "    df.to_csv(output_path, index=False)\n",
    "    \n",
    "    # Report export success\n",
    "    print(f\"Dataset exported to: {output_path}\")\n",
    "    print(f\"Total records: {len(df)}\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# SUMMARY STATISTICS\n",
    "# =============================================================================\n",
    "\n",
    "def print_summary_statistics(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Print comprehensive summary statistics for the final dataset.\n",
    "    \n",
    "    This function provides a quick overview of:\n",
    "    - Dataset size and diversity\n",
    "    - Stability class distribution\n",
    "    - ddG statistics (mean, std, min, max, etc.)\n",
    "    - Mutation position distribution\n",
    "    - Sequence length statistics\n",
    "    \n",
    "    This is useful for:\n",
    "    - Quality control\n",
    "    - Understanding data distribution\n",
    "    - Detecting anomalies\n",
    "    - Documenting dataset characteristics\n",
    "    \n",
    "    Args:\n",
    "        df: Final processed DataFrame\n",
    "        \n",
    "    Example:\n",
    "        >>> print_summary_statistics(df_final)\n",
    "        ============================================================\n",
    "        DATASET SUMMARY STATISTICS\n",
    "        ============================================================\n",
    "        \n",
    "        Total mutations: 375560\n",
    "        Unique proteins (WT): 145\n",
    "        ...\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"DATASET SUMMARY STATISTICS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Basic counts\n",
    "    print(f\"\\nTotal mutations: {len(df)}\")\n",
    "    print(f\"Unique proteins (WT): {df['wt_name'].nunique()}\")\n",
    "    print(f\"Unique clusters: {df['wt_cluster'].nunique()}\")\n",
    "    \n",
    "    # Stability distribution\n",
    "    print(f\"\\nStability distribution:\")\n",
    "    print(df['stability_class'].value_counts().sort_index())\n",
    "    \n",
    "    # ddG statistics (central tendency, spread, range)\n",
    "    print(f\"\\nddG statistics:\")\n",
    "    print(df['ddG'].describe())\n",
    "    \n",
    "    # Mutation position statistics\n",
    "    print(f\"\\nMutation position range:\")\n",
    "    print(f\"  Min: {df['pos'].min()}\")\n",
    "    print(f\"  Max: {df['pos'].max()}\")\n",
    "    print(f\"  Mean: {df['pos'].mean():.2f}\")\n",
    "    \n",
    "    # Sequence length statistics\n",
    "    print(f\"\\nSequence length statistics:\")\n",
    "    seq_lengths = df['mut_seq'].str.len()\n",
    "    print(f\"  Min: {seq_lengths.min()}\")\n",
    "    print(f\"  Max: {seq_lengths.max()}\")\n",
    "    print(f\"  Mean: {seq_lengths.mean():.2f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN EXECUTION\n",
    "# =============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Execute the complete data processing pipeline.\n",
    "    \n",
    "    Pipeline steps:\n",
    "    1. Load raw K50 dataset\n",
    "    2. Select relevant features\n",
    "    3. Filter for single-point mutations\n",
    "    4. Parse mutation annotations\n",
    "    5. Reconstruct wild-type sequences\n",
    "    6. Validate mutations\n",
    "    7. Classify stability effects\n",
    "    8. Prepare final dataset\n",
    "    9. Export to CSV\n",
    "    10. Print summary statistics\n",
    "    \"\"\"\n",
    "    print(\"Starting K50 data processing pipeline...\\n\")\n",
    "    \n",
    "    # Step 1: Load data\n",
    "    print(\"Step 1: Loading raw dataset...\")\n",
    "    df_raw = load_k50_dataset(INPUT_PATH)\n",
    "    print()\n",
    "    \n",
    "    # Step 2: Feature selection\n",
    "    print(\"Step 2: Selecting features...\")\n",
    "    df_selected = select_features(df_raw, FEATURES_TO_KEEP)\n",
    "    print()\n",
    "    \n",
    "    # Step 3: Filter mutations\n",
    "    print(\"Step 3: Filtering for single-point mutations...\")\n",
    "    df_filtered = filter_single_point_mutations(df_selected)\n",
    "    print()\n",
    "    \n",
    "    # Step 4: Parse mutations\n",
    "    print(\"Step 4: Parsing mutation annotations...\")\n",
    "    df_annotated = annotate_mutations(df_filtered)\n",
    "    print()\n",
    "    \n",
    "    # Step 5: Reconstruct WT sequences\n",
    "    print(\"Step 5: Reconstructing wild-type sequences...\")\n",
    "    df_with_wt = add_wt_sequences(df_annotated)\n",
    "    print()\n",
    "    \n",
    "    # Step 6: Validate mutations\n",
    "    print(\"Step 6: Validating mutations...\")\n",
    "    df_validated = add_validation_flags(df_with_wt)\n",
    "    print()\n",
    "    \n",
    "    # Step 7: Classify stability\n",
    "    print(\"Step 7: Classifying stability effects...\")\n",
    "    df_classified = classify_stability(df_validated, threshold=STABILITY_THRESHOLD)\n",
    "    print()\n",
    "    \n",
    "    # Step 8: Prepare final dataset\n",
    "    print(\"Step 8: Preparing final dataset...\")\n",
    "    df_final = prepare_final_dataset(df_classified)\n",
    "    print()\n",
    "    \n",
    "    # Step 9: Export\n",
    "    print(\"Step 9: Exporting cleaned dataset...\")\n",
    "    export_dataset(df_final, OUTPUT_PATH)\n",
    "    print()\n",
    "    \n",
    "    # Step 10: Summary\n",
    "    print(\"Step 10: Generating summary statistics...\")\n",
    "    print_summary_statistics(df_final)\n",
    "    print()\n",
    "    \n",
    "    print(\"Pipeline completed successfully!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
